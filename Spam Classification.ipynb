{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam Classification\n",
    "Based on Andre Ng Lectures.\n",
    "Supervised Learning with SVM from sklearn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Anyone knows how much it costs to host a web portal ?\n",
      ">\n",
      "Well, it depends on how many visitors you're expecting.\n",
      "This can be anywhere from less than 10 bucks a month to a couple of $100. \n",
      "You should checkout http://www.rackspace.com/ or perhaps Amazon EC2 \n",
      "if youre running something big..\n",
      "\n",
      "To unsubscribe yourself from this mailing list, send an email to:\n",
      "groupname-unsubscribe@egroups.com\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def ProcessEmail(email,vocabulary):\n",
    "#   Takes .txt file containing the email and returns the feature vector.\n",
    "#   Performs various operations to clean, tokenize, stem, and index.\n",
    "    with open(email, 'r') as f:\n",
    "        emailContents = f.read()\n",
    "        \n",
    "    WordIndices = []\n",
    "    vocab = pd.read_csv(vocabulary,delimiter='\\t',names=['Index','Word'],index_col=False)\n",
    "    # vocab.head()\n",
    "    emailContents = emailContents.lower() \n",
    "\n",
    "    # Expressions that begin with < and end with >\n",
    "    emailContents = re.sub('<[^<>]+>',' ',emailContents)\n",
    "\n",
    "    emailContents = re.sub('[0-9]+', 'number',emailContents)\n",
    "\n",
    "    emailContents = re.sub('(http|https)://[^\\s]*', 'httpaddr',emailContents)\n",
    "\n",
    "    emailContents = re.sub( '[^\\s]+@[^\\s]+', 'emailaddr',emailContents)\n",
    "\n",
    "    emailContents = re.sub( '[$]+', 'dollar', emailContents) \n",
    "    # Dollar is currently joined to the number\n",
    "    emailContents = re.sub( 'dollarnumber', 'dollar', emailContents) \n",
    "\n",
    "    emailContents = word_tokenize(emailContents)\n",
    "\n",
    "    emailContents = [word for word in emailContents if word.isalpha()]\n",
    "    ps = PorterStemmer()\n",
    "    emailContents = [ps.stem(word) for word in emailContents]\n",
    "\n",
    "    #Remove Short words\n",
    "    emailContents = [word for word in emailContents if len(word)>=2]\n",
    "#     emailContents = ['dollar' for word in emailContents if word =='dollarnumb']\n",
    "    \n",
    "#     print(emailContents)\n",
    "    for word in emailContents:\n",
    "        ind = vocab[vocab['Word'] == word].index.tolist()\n",
    "        if ind:\n",
    "            WordIndices.append(ind[0]+1)\n",
    "#     print(WordIndices)\n",
    "    \n",
    "    # Create Features\n",
    "    n = vocab.shape[0]\n",
    "    X = np.zeros(n)\n",
    "    for ind in WordIndices:\n",
    "        X[ind] = 1\n",
    "#     print(X)\n",
    "    return X.reshape(-1, 1)\n",
    "\n",
    "    \n",
    "X = ProcessEmail('emailSample1.txt','vocab.txt')\n",
    "# X = ProcessEmail('spamSample1.txt','vocab.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Spam Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 1899)\n",
      "Training Accuracy: 0.99825\n"
     ]
    }
   ],
   "source": [
    "rawdata = sio.loadmat('spamTrain.mat',mat_dtype=True)\n",
    "X = rawdata['X']\n",
    "y = rawdata['y'].flatten()\n",
    "print(X.shape)\n",
    "clf = svm.SVC(kernel='linear', C = 0.1) #, gamma=gamma)\n",
    "clf.fit(X, y)\n",
    "Ypred = clf.predict(X)\n",
    "accuracy = np.mean(np.equal(y,Ypred))\n",
    "print('Training Accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.989\n"
     ]
    }
   ],
   "source": [
    "# Verify accuracy with test data\n",
    "rawdata = sio.loadmat('spamTest.mat',mat_dtype=True)\n",
    "Xtest = rawdata['Xtest']\n",
    "ytest = rawdata['ytest'].flatten()\n",
    "Ypred = clf.predict(Xtest)\n",
    "accuracy = np.mean(np.equal(ytest,Ypred))\n",
    "print('Test Accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What were the top classifiers of spam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " spamassassin     (-0.605132) \n",
      "\n",
      " the              (-0.438072) \n",
      "\n",
      " url              (-0.428355) \n",
      "\n",
      " wrote            (-0.409923) \n",
      "\n",
      " date             (-0.405492) \n",
      "\n",
      " list             (-0.361847) \n",
      "\n",
      " rpm              (-0.352484) \n",
      "\n",
      " numbertnumb      (-0.327918) \n",
      "\n",
      " user             (-0.322528) \n",
      "\n",
      " until            (-0.315433) \n",
      "\n",
      " author           (-0.308427) \n",
      "\n",
      " razor            (-0.301497) \n",
      "\n",
      " yahoo            (-0.275555) \n",
      "\n",
      " tom              (-0.269043) \n",
      "\n",
      " httpaddr         (-0.268191) \n",
      "\n",
      " jim              (-0.253419) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "weight, ind = np.sort(clf.coef_),np.argsort(clf.coef_)\n",
    "\n",
    "weight,ind  = weight[0],ind[0]\n",
    "\n",
    "for i in range(0,16):\n",
    "    print(' %-15s  (%f) \\n' %(vocab.iloc[ind[i],1],weight[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict a New email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Buy Viagra Generic Online\n",
      "\n",
      "Viagra 100mg x 60 Pills $125, Free Pills & Reorder Discount, Top Selling 100% Quality & Satisfaction guaranteed!\n",
      "\n",
      "We accept VISA, Master & E-Check Payments, 90000+ Satisfied Customers!\n",
      "http://medphysitcstech.ru\n",
      "\n",
      "\n",
      "\n",
      "Is spam? 0-not spam | 1-is spam\n",
      " [1.]\n"
     ]
    }
   ],
   "source": [
    "newemail = 'spamSample2.txt'\n",
    "Xm = ProcessEmail(newemail,'vocab.txt')\n",
    "Predic = clf.predict(Xm.T)\n",
    "print('Is spam? 0-not spam | 1-is spam\\n',Predic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
